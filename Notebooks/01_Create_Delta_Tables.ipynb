{"cells":[{"cell_type":"markdown","source":["## Spark session configuration\n"," This cell sets Spark session settings to enable Verti-Parquet and Optimize on Write. More details about Verti-Parquet and Optimize on Write in tutorial document."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b74f943a-1cff-449c-b7a0-1c27b4fc157b"},{"cell_type":"code","source":["# Copyright (c) Microsoft Corporation.\n","# Licensed under the MIT License.\n","\n","spark.conf.set(\"spark.sql.parquet.vorder.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.enabled\", \"true\")\n","spark.conf.set(\"spark.microsoft.delta.optimizeWrite.binSize\", \"1073741824\")"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":3,"statement_ids":[3],"livy_statement_state":"available","session_id":"a1d124d9-0fc1-4f2e-bb8a-efac616518c9","state":"finished","normalized_state":"finished","queued_time":"2024-07-15T12:47:44.0271228Z","session_start_time":"2024-07-15T12:47:44.2925771Z","execution_start_time":"2024-07-15T12:47:55.852252Z","execution_finish_time":"2024-07-15T12:47:58.4951284Z","parent_msg_id":"34520467-4744-47b2-a0e6-2e26a3d34dab"},"text/plain":"StatementMeta(, a1d124d9-0fc1-4f2e-bb8a-efac616518c9, 3, Finished, Available, Finished)"},"metadata":{}}],"execution_count":1,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"adc5fa00-1d9d-45b9-8417-c3d4e3515264"},{"cell_type":"markdown","source":["## Load your DataFrame"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c3a2ce92-4148-48c6-9cc1-accb008bbb91"},{"cell_type":"code","source":["df = spark.read.parquet(\"Files\")\n","print(df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":4,"statement_ids":[4],"livy_statement_state":"available","session_id":"a1d124d9-0fc1-4f2e-bb8a-efac616518c9","state":"finished","normalized_state":"finished","queued_time":"2024-07-15T12:47:44.1445384Z","session_start_time":null,"execution_start_time":"2024-07-15T12:47:58.8989446Z","execution_finish_time":"2024-07-15T12:48:06.1224508Z","parent_msg_id":"5bffa9bc-77bb-4c4f-b343-72f24669b8d9"},"text/plain":"StatementMeta(, a1d124d9-0fc1-4f2e-bb8a-efac616518c9, 4, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DataFrame[vendorID: int, lpepPickupDatetime: timestamp, lpepDropoffDatetime: timestamp, passengerCount: int, tripDistance: double, puLocationId: string, doLocationId: string, pickupLongitude: double, pickupLatitude: double, dropoffLongitude: double, dropoffLatitude: double, rateCodeID: int, storeAndFwdFlag: string, paymentType: int, fareAmount: double, extra: double, mtaTax: double, improvementSurcharge: string, tipAmount: double, tollsAmount: double, ehailFee: double, totalAmount: double, tripType: int, puYear: int, puMonth: int]\n"]}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"5a039b68-a3d1-437b-8edb-0f54b8d0cb47"},{"cell_type":"markdown","source":["## Date Dimension Table"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"012f3f67-a6f9-4c1b-ad38-dd408d00f3df"},{"cell_type":"code","source":["from pyspark.sql.functions import col, year, month, quarter\n","\n","table_name = 'fact_trip'\n","\n","df = df.withColumn('Year', year(col(\"lpepDropoffDatetime\")))\n","df = df.withColumn('Quarter', quarter(col(\"lpepDropoffDatetime\")))\n","df = df.withColumn('Month', month(col(\"lpepDropoffDatetime\")))\n","\n","df.write.mode(\"overwrite\").format(\"delta\").partitionBy(\"Year\",\"Quarter\").save(\"Tables/\" + table_name)\n","     "],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":5,"statement_ids":[5],"livy_statement_state":"available","session_id":"a1d124d9-0fc1-4f2e-bb8a-efac616518c9","state":"finished","normalized_state":"finished","queued_time":"2024-07-15T12:47:44.3098685Z","session_start_time":null,"execution_start_time":"2024-07-15T12:48:06.5184667Z","execution_finish_time":"2024-07-15T12:50:04.6569517Z","parent_msg_id":"18dc1218-3e2b-4967-be23-dd7fe19b3bd2"},"text/plain":"StatementMeta(, a1d124d9-0fc1-4f2e-bb8a-efac616518c9, 5, Finished, Available, Finished)"},"metadata":{}}],"execution_count":3,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"29ce1022-5a02-4c4d-a65f-041359d595b4"},{"cell_type":"code","source":["print(df)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":9,"statement_ids":[9],"livy_statement_state":"available","session_id":"a1d124d9-0fc1-4f2e-bb8a-efac616518c9","state":"finished","normalized_state":"finished","queued_time":"2024-07-15T12:54:51.3557069Z","session_start_time":null,"execution_start_time":"2024-07-15T12:54:51.7599724Z","execution_finish_time":"2024-07-15T12:54:52.1094289Z","parent_msg_id":"675328fd-b597-463c-971d-d33bae30eb1f"},"text/plain":"StatementMeta(, a1d124d9-0fc1-4f2e-bb8a-efac616518c9, 9, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DataFrame[vendorID: int, lpepPickupDatetime: timestamp, lpepDropoffDatetime: timestamp, passengerCount: int, tripDistance: double, puLocationId: string, doLocationId: string, pickupLongitude: double, pickupLatitude: double, dropoffLongitude: double, dropoffLatitude: double, rateCodeID: int, storeAndFwdFlag: string, paymentType: int, fareAmount: double, extra: double, mtaTax: double, improvementSurcharge: string, tipAmount: double, tollsAmount: double, ehailFee: double, totalAmount: double, tripType: int, puYear: int, puMonth: int]\n"]}],"execution_count":7,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0fc78cb4-a7ba-47ae-85cf-43354ad4ec2e"},{"cell_type":"markdown","source":["## **Dimensions**\n","This cell creates a function to read raw data from the Files section of the lakehouse for the table name passed as a parameter. Next, it creates a list of dimension tables. Finally, it has a for loop to loop through the list of tables and call above function with each table name as parameter to read data for that specific table and create delta table."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fd19d037-f72d-4aa7-a2e1-f0f721554a47"},{"cell_type":"code","source":["# Load your DataFrame\n","df = spark.read.format(\"parquet\").load('Files')"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":11,"statement_ids":[11],"livy_statement_state":"available","session_id":"a1d124d9-0fc1-4f2e-bb8a-efac616518c9","state":"finished","normalized_state":"finished","queued_time":"2024-07-15T12:55:34.7439001Z","session_start_time":null,"execution_start_time":"2024-07-15T12:55:35.1410082Z","execution_finish_time":"2024-07-15T12:55:42.3346084Z","parent_msg_id":"85d7aa1c-fc6b-4fc7-bf54-4ae837720598"},"text/plain":"StatementMeta(, a1d124d9-0fc1-4f2e-bb8a-efac616518c9, 11, Finished, Available, Finished)"},"metadata":{}}],"execution_count":9,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"29022b99-76d3-4cba-a6be-3188b85e15be"},{"cell_type":"code","source":["print(df.select(\"lpepPickupDatetime\"))"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":13,"statement_ids":[13],"livy_statement_state":"available","session_id":"a1d124d9-0fc1-4f2e-bb8a-efac616518c9","state":"finished","normalized_state":"finished","queued_time":"2024-07-15T12:56:07.7720377Z","session_start_time":null,"execution_start_time":"2024-07-15T12:56:08.1986363Z","execution_finish_time":"2024-07-15T12:56:08.5489873Z","parent_msg_id":"67dfe9f5-a3b7-494f-b224-2ff033623a76"},"text/plain":"StatementMeta(, a1d124d9-0fc1-4f2e-bb8a-efac616518c9, 13, Finished, Available, Finished)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["DataFrame[lpepPickupDatetime: timestamp]\n"]}],"execution_count":11,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"39065727-29b6-4618-bacc-908201b79903"},{"cell_type":"code","source":["from pyspark.sql import SparkSession\n","from pyspark.sql.functions import col, year, month, dayofmonth, dayofweek, hour, minute, second, when\n","\n","# Load your DataFrame\n","df = spark.read.format(\"parquet\").load('Files')\n","df = df.select([c for c in df.columns if c != 'Photo'])\n","\n","# Function to create and save dimension tables\n","def create_and_save_dimension(df, table_name, columns, transformations=[]):\n","    dimension_df = df\n","    for transformation in transformations:\n","        dimension_df = transformation(dimension_df)\n","    dimension_df = dimension_df.select(columns).distinct()\n","    dimension_df.write.mode(\"overwrite\").format(\"delta\").save(\"Tables/\" + table_name)\n","\n","# Define the transformations\n","def date_transformations(df):\n","    return df.withColumn(\"Day\", dayofmonth(col(\"lpepPickupDatetime\"))) \\\n","             .withColumn(\"Month\", month(col(\"lpepPickupDatetime\"))) \\\n","             .withColumn(\"Year\", year(col(\"lpepPickupDatetime\"))) \\\n","             .withColumn(\"DayOfWeek\", dayofweek(col(\"lpepPickupDatetime\"))) \\\n","             .withColumn(\"IsWeekend\", when(col(\"DayOfWeek\").isin([7, 1]), \"Yes\").otherwise(\"No\"))\n","\n","def time_transformations(df):\n","    return df.withColumn(\"Hour\", hour(col(\"lpepPickupDatetime\"))) \\\n","             .withColumn(\"Minute\", minute(col(\"lpepPickupDatetime\"))) \\\n","             .withColumn(\"Second\", second(col(\"lpepPickupDatetime\"))) \\\n","             .withColumn(\"PeriodOfDay\", when(col(\"Hour\") < 6, \"Night\")\n","                                      .when((col(\"Hour\") >= 6) & (col(\"Hour\") < 12), \"Morning\")\n","                                      .when((col(\"Hour\") >= 12) & (col(\"Hour\") < 18), \"Afternoon\")\n","                                      .otherwise(\"Evening\"))\n","\n","# Define the dimensions\n","dimensions = [\n","    {\n","        'table_name': 'dimension_date',\n","        'columns': [\"Date\", \"Day\", \"Month\", \"Year\", \"DayOfWeek\", \"IsWeekend\"],\n","        'transformations': [date_transformations]\n","    },\n","    {\n","        'table_name': 'dimension_time',\n","        'columns': [\"Time\", \"Hour\", \"Minute\", \"Second\", \"PeriodOfDay\"],\n","        'transformations': [time_transformations]\n","    },\n","    {\n","        'table_name': 'dimension_vendor',\n","        'columns': [\"vendorID\"]\n","    }\n","]\n","\n","# Create and save each dimension table\n","for dimension in dimensions:\n","    if 'transformations' in dimension:\n","        df_transformed = df.withColumn(\"Date\", col(\"lpepPickupDatetime\")).withColumn(\"Time\", col(\"lpepPickupDatetime\"))\n","        create_and_save_dimension(df_transformed, dimension['table_name'], dimension['columns'], dimension['transformations'])\n","    else:\n","        create_and_save_dimension(df, dimension['table_name'], dimension['columns'])\n"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"statement_id":15,"statement_ids":[15],"livy_statement_state":"running","session_id":"a1d124d9-0fc1-4f2e-bb8a-efac616518c9","state":"submitted","normalized_state":"running","queued_time":"2024-07-15T12:57:54.2508552Z","session_start_time":null,"execution_start_time":"2024-07-15T12:57:54.6562588Z","execution_finish_time":null,"parent_msg_id":"2ad3e654-4c66-4d9a-8e2d-57ca6434be5a"},"text/plain":"StatementMeta(, a1d124d9-0fc1-4f2e-bb8a-efac616518c9, 15, Submitted, Running, Running)"},"metadata":{}}],"execution_count":13,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7152486f-eafa-4565-83e2-91450b8cb0fd"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":"30e2b793-2a3c-4823-8930-60409f073e82","known_lakehouses":[{"id":"30e2b793-2a3c-4823-8930-60409f073e82"}],"default_lakehouse_name":"Bronze","default_lakehouse_workspace_id":"6b4a8b01-935b-41ea-bcb4-cb109074c3d2"}}},"nbformat":4,"nbformat_minor":5}
